{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using LSTM (Bi-Di)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Tokenizer and pad_sequences\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "dataset = pd.read_csv('/Users/avaneeshkumar/Downloads/Docker/DL/NLP-using-tf/NLP/combined_data.csv')\n",
    "\n",
    "# Extract out sentences and labels\n",
    "sentences = dataset['text'].tolist()\n",
    "labels = dataset['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is  999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocab_size = 1000\n",
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(sentences, vocab_size, max_subword_length=5)\n",
    "\n",
    "# How big is the vocab size?\n",
    "print(\"Vocab size is \", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have to jiggle the plug to get it to line up right to get decent volume.\n",
      "[4, 31, 6, 849, 162, 450, 12, 1, 600, 438, 775, 6, 175, 14, 6, 55, 213, 159, 474, 775, 6, 175, 614, 380, 295, 148, 72, 789]\n",
      "I \n",
      "have \n",
      "to \n",
      "j\n",
      "ig\n",
      "gl\n",
      "e \n",
      "the \n",
      "pl\n",
      "ug\n",
      " \n",
      "to \n",
      "get \n",
      "it \n",
      "to \n",
      "li\n",
      "ne \n",
      "up \n",
      "right\n",
      " \n",
      "to \n",
      "get \n",
      "dec\n",
      "ent \n",
      "vo\n",
      "lu\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Check that the tokenizer works appropriately\n",
    "num = 5\n",
    "print(sentences[num])\n",
    "encoded = tokenizer.encode(sentences[num])\n",
    "print(encoded)\n",
    "\n",
    "\n",
    "# Separately print out each subword, decoded\n",
    "for i in encoded:\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace sentence data with encoded subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    sentences[i] = tokenizer.encode(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Preporcessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_length = 50\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "# Pad all sequences\n",
    "sequences_padded = pad_sequences(sentences, maxlen=max_length, \n",
    "                                 padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Separate out the sentences and labels into training and test sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "\n",
    "training_sequences = sequences_padded[0:training_size]\n",
    "testing_sequences = sequences_padded[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "# Make labels into numpy arrays for use with the network later\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "# Define the model\n",
    "model_bidi_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)), \n",
    "    tf.keras.layers.Dense(6, activation='relu'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1593 samples, validate on 399 samples\n",
      "Epoch 1/20\n",
      "1593/1593 [==============================] - 17s 10ms/sample - loss: 0.6928 - accuracy: 0.5097 - val_loss: 0.6962 - val_accuracy: 0.4110\n",
      "Epoch 2/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.6881 - accuracy: 0.5499 - val_loss: 0.6776 - val_accuracy: 0.7018\n",
      "Epoch 3/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.6167 - accuracy: 0.7313 - val_loss: 0.5728 - val_accuracy: 0.7494\n",
      "Epoch 4/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.4655 - accuracy: 0.8110 - val_loss: 0.5356 - val_accuracy: 0.7619\n",
      "Epoch 5/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.3525 - accuracy: 0.8675 - val_loss: 0.4867 - val_accuracy: 0.7794\n",
      "Epoch 6/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.2692 - accuracy: 0.9083 - val_loss: 0.5329 - val_accuracy: 0.7594\n",
      "Epoch 7/20\n",
      "1593/1593 [==============================] - 7s 5ms/sample - loss: 0.2240 - accuracy: 0.9247 - val_loss: 0.5503 - val_accuracy: 0.7744\n",
      "Epoch 8/20\n",
      "1593/1593 [==============================] - 7s 4ms/sample - loss: 0.1947 - accuracy: 0.9385 - val_loss: 0.6326 - val_accuracy: 0.7594\n",
      "Epoch 9/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.1606 - accuracy: 0.9504 - val_loss: 0.7124 - val_accuracy: 0.7544\n",
      "Epoch 10/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.1423 - accuracy: 0.9630 - val_loss: 0.7646 - val_accuracy: 0.7544\n",
      "Epoch 11/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.1172 - accuracy: 0.9724 - val_loss: 0.7829 - val_accuracy: 0.7519\n",
      "Epoch 12/20\n",
      "1593/1593 [==============================] - 7s 5ms/sample - loss: 0.1241 - accuracy: 0.9686 - val_loss: 0.8088 - val_accuracy: 0.7444\n",
      "Epoch 13/20\n",
      "1593/1593 [==============================] - 9s 6ms/sample - loss: 0.1261 - accuracy: 0.9636 - val_loss: 0.7797 - val_accuracy: 0.7669\n",
      "Epoch 14/20\n",
      "1593/1593 [==============================] - 7s 5ms/sample - loss: 0.0963 - accuracy: 0.9774 - val_loss: 0.9716 - val_accuracy: 0.7444\n",
      "Epoch 15/20\n",
      "1593/1593 [==============================] - 9s 6ms/sample - loss: 0.0740 - accuracy: 0.9831 - val_loss: 0.9980 - val_accuracy: 0.7594\n",
      "Epoch 16/20\n",
      "1593/1593 [==============================] - 8s 5ms/sample - loss: 0.0579 - accuracy: 0.9881 - val_loss: 1.0838 - val_accuracy: 0.7494\n",
      "Epoch 17/20\n",
      "1593/1593 [==============================] - 7s 4ms/sample - loss: 0.0485 - accuracy: 0.9918 - val_loss: 1.1227 - val_accuracy: 0.7544\n",
      "Epoch 18/20\n",
      "1593/1593 [==============================] - 6s 4ms/sample - loss: 0.0420 - accuracy: 0.9931 - val_loss: 1.1503 - val_accuracy: 0.7494\n",
      "Epoch 19/20\n",
      "1593/1593 [==============================] - 7s 4ms/sample - loss: 0.0371 - accuracy: 0.9937 - val_loss: 1.1963 - val_accuracy: 0.7594\n",
      "Epoch 20/20\n",
      "1593/1593 [==============================] - 7s 4ms/sample - loss: 0.0385 - accuracy: 0.9918 - val_loss: 1.2859 - val_accuracy: 0.7343\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 20\n",
    "model_bidi_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model_bidi_lstm.fit(training_sequences, training_labels_final, epochs=num_epochs, validation_data=(testing_sequences, testing_labels_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLotting the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_reviews =[\"lovely\", \"dreadful\", \"stay away\",\n",
    "             \"everything was hot exactly as I wanted\",\n",
    "             \"everything was not exactly as I wanted\",\n",
    "             \"they gave us free chocolate cake\",\n",
    "             \"I've never eaten anything so spicy in my life, my throat burned for hours\",\n",
    "             \"for a phone that is as expensive as this one I expect it to be much easier to use than this thing is\",\n",
    "             \"we left there very full for a low price so I'd say you just can't go wrong at this place\",\n",
    "             \"that place does not have quality meals and it isn't a good place to go for dinner\",\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===================================\\n\", \"With a single bidirectional LSTM:\\n\", \"===================================\")\n",
    "predict_review(model_bidi_lstm, my_reviews, show_padded_sequence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
